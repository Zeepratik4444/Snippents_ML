{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhsnyLBVM7Efp+wD05ALKd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zeepratik4444/Snippents_ML/blob/main/Deep_Learning_HelpBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Genral class module for torchVision"
      ],
      "metadata": {
        "id": "aVIntLkQr2tX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_32IUDRGj5w"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "from torch import nn\n",
        "class FashionMNISTV2(nn.Module):\n",
        "  \"\"\"\n",
        "  Model arcitechture that replicates the TinyVGG\n",
        "  Model from CNN explainer website.\n",
        "  \"\"\"\n",
        "  def __init__(self,input_shape:int,hidden_units:int,output_shape:int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride=1,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2=nn.Sequential(\n",
        "      nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride=1,padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride=1,padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier=nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(in_features=hidden_units*7*7,out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv_block_1(x)\n",
        "    x=self.conv_block_2(x)\n",
        "    x=  self.classifier(x)\n",
        "    return(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training function for training model and let it learn."
      ],
      "metadata": {
        "id": "3eOUJSeNsDe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mode(model:torch.nn.Module,\n",
        "               train_data_loader:torch.utils.data.DataLoader,\n",
        "               test_data_loader: torch.utils.data.DataLoader,\n",
        "               loss: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               epochs: int,\n",
        "               device: torch.device = device,\n",
        "               ):\n",
        "  start_time=timer()\n",
        "  total_loss,total_acc=0,0\n",
        "  model.to(device)\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    for batch ,(x_train,y_train) in enumerate(train_data_loader):\n",
        "      x_train,y_train=x_train.to(device),y_train.to(device)\n",
        "      model.train()\n",
        "      y_pred=model(x_train)\n",
        "      loss= loss_fn(y_pred,y_train)\n",
        "      total_loss+=loss\n",
        "      total_acc+=accuracy_fn(y_train,y_pred.argmax(dim=1))\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    total_loss/=len(train_data_loader)\n",
        "    total_acc/=len(train_data_loader)\n",
        "    if batch % 400==0:\n",
        "      print(f\"Looked at {batch* len(x)}/{len(train_data.dataset)} samples.\")\n",
        "    #Testing\n",
        "    test_loss,test_acc=0,0\n",
        "    with torch.inference_mode():\n",
        "      for x_test, y_test in test_data_loader:\n",
        "        # Send data to GPU\n",
        "        x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        test_pred = model(x_test)\n",
        "\n",
        "        # 2. Calculate loss and accuracy\n",
        "        test_loss += loss_fn(test_pred, y_test)\n",
        "        test_acc += accuracy_fn(y_true=y_test,\n",
        "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
        "            )\n",
        "      test_loss/= len(test_data_loader)\n",
        "      test_acc/=len(test_data_loader)\n",
        "  end_time=timer()\n",
        "  time_taken=end_time-start_time\n",
        "\n",
        "  print(f\"Train Loss : {total_loss:.5f} , Train Acc : {total_acc} \\n Test Loss :{test_loss:.5f}  ,Test Acc : {test_acc:.2f}% \\n Time Taken : {time_taken:.3f} Seconds\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kkReNcGBrzJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. To make torchvision predictions"
      ],
      "metadata": {
        "id": "lYkdtdFqtw_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model:torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device=device):\n",
        "  pred_probs=[]\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # Preparing the sample( add a batch dimension and pass to target device)\n",
        "      sample=torch.unsqueeze(sample,dim=0).to(device)\n",
        "      # FOrward pass (model outputs raw logits)\n",
        "      pred_logits=model(sample)\n",
        "      # get prediction probability ( logit-> prediction probability)\n",
        "      pred_prob= torch.softmax(pred_logits.squeeze(),dim=0)\n",
        "      # Get pred_prob off the GPU for further calcualtions\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        " # Stack the pred_probs to turn list into a tesnor\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "TzNqrv4Ot4TB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}